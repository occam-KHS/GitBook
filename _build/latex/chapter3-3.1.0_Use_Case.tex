%% Generated by Sphinx.
\def\sphinxdocclass{jupyterBook}
\documentclass[letterpaper,10pt,english]{jupyterBook}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}
%% turn off hyperref patch of \index as sphinx.xdy xindy module takes care of
%% suitable \hyperpage mark-up, working around hyperref-xindy incompatibility
\PassOptionsToPackage{hyperindex=false}{hyperref}
%% memoir class requires extra handling
\makeatletter\@ifclassloaded{memoir}
{\ifdefined\memhyperindexfalse\memhyperindexfalse\fi}{}\makeatother

\PassOptionsToPackage{warn}{textcomp}

\catcode`^^^^00a0\active\protected\def^^^^00a0{\leavevmode\nobreak\ }
\usepackage{cmap}
\usepackage{fontspec}
\defaultfontfeatures[\rmfamily,\sffamily,\ttfamily]{}
\usepackage{amsmath,amssymb,amstext}
\usepackage{polyglossia}
\setmainlanguage{english}



\setmainfont{FreeSerif}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Italic,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldItalic
]
\setsansfont{FreeSans}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]
\setmonofont{FreeMono}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]



\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=1,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}



        % Start of preamble defined in sphinx-jupyterbook-latex %
         \usepackage[Latin,Greek]{ucharclasses}
        \usepackage{unicode-math}
        % fixing title of the toc
        \addto\captionsenglish{\renewcommand{\contentsname}{Contents}}
        \hypersetup{
            pdfencoding=auto,
            psdextra
        }
        % End of preamble defined in sphinx-jupyterbook-latex %
        

\title{데이터분석 활용사례}
\date{Jul 02, 2022}
\release{}
\author{KHS}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{chapter3/3.1.0_Use_Case::doc}}


\sphinxAtStartPar
데이터 분석이 현장에서 어떻게 활용되고 있는 지 산업별로 케이스를 만들어 보았습니다.


\part{보험사 사례}
\label{\detokenize{chapter3/3.1.1_Use_Case:id1}}\label{\detokenize{chapter3/3.1.1_Use_Case::doc}}
\sphinxAtStartPar
산업 분야과 관계없이 데이터분석가로 일하는 과정은 대부분 비슷한 일련의 과정을 겪습니다.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
문제점 파악

\item {} 
\sphinxAtStartPar
정보 수집 및 전문가 인터뷰

\item {} 
\sphinxAtStartPar
가설 설정

\item {} 
\sphinxAtStartPar
가설 검증을 위한 데이터 수집 및 분석

\item {} 
\sphinxAtStartPar
검정과정에서 발견된 결과을 이용하여 해결책 개발

\item {} 
\sphinxAtStartPar
해결책 테스트 및 해결책의 효과 측정

\end{enumerate}

\sphinxAtStartPar
쉬운 이해를 위하여 보험회사 사례를 들어보겠습니다. 보험회사 영업회의 시간입니다. 영업 상무님이 코로나로 대면 채널이 어려워 텔레마케팅을 시도해 볼 계획인데, 워낙 반응율이 낮아(반응율 1\%, 즉 100 명에게 전화하면 1명이 보험가입), 걱정이라고 하십니다. 그리고 신입 데이터사이언티스인 홍철에게 좋은 방법이 있겠냐고 물어봅니다. 홍철은 고민하다가

\sphinxAtStartPar
(1) 문제점파악: 전화로 보험을 잘 구매할 고객 군을 타겟팅해서 텔레마케팅을 하면 어떻겠냐고 대답합니다. 상무님은 그게 된다면 좋겠지만, 가능하겠냐고 반문하셨고. 이런 저런 이야기로 회의가 마무리 되었습니다. 홍철은 회의 후 자리로 돌아와 고민에 빠졌습니다. 신입으로 데이터사이언티스의 가치를 보여줄 좋은 기회인데, 어떻게 텔레마케팅에 반응율이 좋은 고객군을 찾아낼 수 있을까?

\sphinxAtStartPar
(2) 정보 수집 및 전문가 인터뷰: 일단 전화영업 담당자 인터뷰를 통해 관련 지식과 가설 설정에 도움이 될 만한 정보를 수집해 봅니다. 전화영업 담당자는 주로 인구통계에 의한 결과를 공유해 줍니다. 고령자고, 남성이 더 반응율이 좋다고 합니다. 아주 좋은 정보를 얻었습니다. 또 다른 담당자를 만났습니다. 이 분은 누구에게 전화를 하는 것보다는 어떤 텔레마케터가 전화를 하느냐가 더 중요하다고 합니다. 성과가 좋은 텔레마케터는 연령대에 상관없이 좋은 반응율을 보인다고 합니다. 또 좋은 정보를 얻었습니다. 텔레마케터 지인이 있어, 개인적으로 만나봤습니다. 이 분은 일단 전화를 받을 시간이 있는 사람에게 전화를 해야 한다고 합니다. 아무래도 블루칼라보다는 사무직이 전화받을 시간이 있는 것 같다라고 귀띰을 해 줍니다. 홍철은 소득에 관련해서도 물어봅니다. 하지만 전화를 받는 사람의 소득은 잘 모르겠다고 합니다.

\sphinxAtStartPar
(3)  가설 설정: 현재까지 정보를 바탕으로 몇 가지 가설을 세웁니다.​ 여기서 가설이란 “아마 이런 이유일 때문일 것이다” 하고 추정해보는 것입니다. 예를 들어 의사가 환자를 진단하는 절차도 비슷할 것입니다. 환자가 들어왔습니다. “아랫 배 많이 아픕니다” 라고 이야기를 합니다. 그러면, 의사는 (1) 상한 음식을 먹어서 장염이 발생했나? (2) 화장실을 자주 못가서 그렇나? (3) 아랫 배에 충격이 있었나? 등 여러가지 가설을 설정하고 환자와의 대화를 통하여 해답을 얻을 것입니다.

\sphinxAtStartPar
텔레마케터 담당자와 인터뷰를 통하여 새울 수 있는 가설은 아래와 같습니다. 좋은 가설은 업무 경험에서 나옵니다.
\begin{itemize}
\item {} 
\sphinxAtStartPar
고령자일수록, 남성일 수록 반응율이 좋다.

\item {} 
\sphinxAtStartPar
반응율은 연령대와 상관없이 텔레마케터의 능력에 달려있다.

\item {} 
\sphinxAtStartPar
전화를 받을 시간적 여유가 있는 사람이 반응율이 좋다.

\item {} 
\sphinxAtStartPar
소득이 많을 수록 반응율이 좋다.

\end{itemize}

\sphinxAtStartPar
위 가설을 증명하기 위해서는 데이터를 수집해야 합니다. 하지만, 신규고객을 대상으로 테스트 마케팅을 하지 않는 이상, 위 정보를 얻을 수 는 없습니다. 가장 좋은 방법은 기존 고객을 대상으로 한 과거 캠페인 데이터를 수집하는 것입니다. 과거 기존 고객을 대상으로 한 캠페인 로그파일을 추출합니다. 기존 고객을 대상으로 교차판매 캠페인이므로 반응(신규 보험가입) 여부와 고객 프로파일이 존재합니다.
​
(4) 가설 검증을 위한 데이터 수집 및 분석:  연령별, 성별로 반응율은 분석합니다. 각 텔레마케터 별 연령, 성별 분석도 합니다. 텔레마케터의 프로파일과 대상고객사의 프로파일도 비교합니다. 시간적인 여유가 있는 고객인지는 모르겠습니다. 하지만, 직업군으로 추정해볼 수있습니다. 다행이 보험심사에 수집한 직업군 정보가 있습니다. 사무직이 현장직보다는 시간적인 여유가 있을 거라고 생각합니다. 직업군별로 반응율을 분석합니다. 또 고객의 소득은 모르겠습니다. 하지만, 거주지의 특성으로 소득을 추정해 봅니다. 상식적으로 도곡동 타워팰리스 거주자가 중소도시 아파트 거주자보다는 고소득일 확율이 높습니다.

\sphinxAtStartPar
(5) 검정과정에서 발견된 결과를 이용하여 해결책 개발: 가설 검정 분석에서 여러가지 분석결과를 얻었습니다. 연령별, 성별 평균 반응율, 직업군별 평균 반응율, 소득별 평균 반응율이 알게 되었습니다. 반응율에 유의미한 변수(피쳐) 등을 알아내었고, 반응율이 높은 고객군을 만들어보기로 하였습니다. 분류할 변수가 많아 고객군을 추출하기가 좀 어렵습니다. 이를 해결하기 위해 통계 스코어링 모델을 만들기로 합니다. 반응은 예/아니오는 이진 분류이므로 로지스틱회귀모델을 만들어서 고객 스코어링를 합니다. 그리고 스코어가 높은 순으로 마케팅 대상고객을 선정합니다.

\sphinxAtStartPar
(6) 해결책 테스트 및 해결책의 효과 측정: 로지스틱 회귀모델이 얼마나 효과있는 지 알기 위해서 약 1천명의 고객은 랜덤하게 추출하고, 1천명은 모델 스코어에 의해 추출합니다. 그리고 테스트 텔레마케팅을 하고 반응율의 차이를 비교합니다. 랜덤하게 뽑힌 대상은 이전과 동일하게 1\%의 반응율을 보였고, 모델을 통하여 뽑인 대상은 2\% 반응율을 보였습니다. 즉 2천명을 랜덤하게 뽑았으면 20명의 신규고객을 얻었을 것이고, 회귀 모델로 2천명을 뽑았으면 40명의 고객이 생겼을 것입니다. 이 번 캠페인에서는 천명씩 테스트 했으므로 30명(10명 + 20명) 의 고객이 생겼습니다. 즉 모델로 10명의 고객을 더 획득하였고, 한 고객이 가져오는 현금흐름의 현재가치가 100 만원이라면, 이번 테스트 마케팅에서 보여준 모델의 가치는 1천만원 됩니다.

\sphinxAtStartPar
참고로 데이터분석가 해결책을 만드는 방법은 맥킨지 컨설팅이 해결책을 제시하는 방법과 유사합니다. 맥킨지 컨설팅이 고객의 문제를 해결하기 위해서는 중요하게 생각하는 3 요소는 다음과 같습니다. 첫번째, 선입견없이 아무것도 모른다고 생각하고 문제에 접근할 것(zero based), 두 번째, 생각을 MECE(Mutually Exclusive Collectively Exhaustive) 하게 구조화할 것. 세번째, 가설기반으로 분석하고 해결책을 만들 것(Hypothesis driven). 이 중에 세번째가 빠르게 해결책을 찾는 핵심입니다. 데이터 마이닝이라는 접근법도 있습니다. 가능한 모든데이터를 한 곳에 집중시켜 분석함으로써 알 수 없었던 새로운 통찰을 알아내는 방법인데요. 대표적인 예가 월마트의 기저기와 맥주 에피소드(별도 에피소드 설명)입니다. 하지만, 이 방법은 시간이 오래걸리고, 유의미한 결과를 얻지 못하는 경우도 종종 있습니다. 사례 3 번에서 간단하게 소개하도록 하겠습니다.


\part{신용카드사 사례}
\label{\detokenize{chapter3/3.1.2_Use_Case:id1}}\label{\detokenize{chapter3/3.1.2_Use_Case::doc}}
\sphinxAtStartPar
이 번 사례는 약간 기술적인 내용을 다루어 보겠습니다. 김대리는 머신러닝 석사를 취득하고, 신용카드 사에 입사한 인재입니다. 김대리는 고객데이터 분석을 통해 신용카드 신청자의 연체가능성을 추정하고, 이에 따라 신용카드의 신용한도를 결정하는 신용관리 부서에서 일하고 있습니다. 보통 신용한도는 연체 가능성에 따라 결정하게 됩니다. 연체가능성이 낮으면 높은 신용한도를, 연체가능성이 높으면 낮은 신용한도를 받게 되는 것입니다. 연체 가능성을 파악하기 위해서 신용카드 신청자의 다양한 정보를 분석합니다. 크게 두 가지 데이터 소스가 있습니다. 카드 발급 신청서에 기입한 개인 정보와 크레딧 뷰로우(신용 금융 정보를 집중 관리 하는 기관) 데이터입니다. 신용카드 신청서에는 연령, 성별, 주소, 직업 등의 정보를 기입하도록 되어 있습니다. 크레딧 뷰로우에서는 신청자의 타 은행 신용 정보가 공유되고 있습니다. 대출을 받아보신 분은 경험하셨을 것이라고 생각합니다. 대출 신청을 하면, 담당 금융사는 타 금융사의 대출정보도 조회할 수 있습니다. 이 정보를 크레딧뷰로우가 제공하게 됩니다. 신용 대출액 혹은 카드 현금서비스 사용여부 등이 대표적인 예입니다. 신용카드사에서는 이런 모든 정보를 종합하여 정교한 연체 확률 모델을 개발, 관리하고 있으며, 신규 가입 요청이 들어오면, 신청자의 데이터가 연체 확률 예측 모델의 입력변수로 들어가게 되고, 예측 모델은 연체 확률을 추정하게 됩니다. 연체 예측 모델을 만들기 위해 신용관리 부서에서는 다양한 가설 검증과 데이터 분석으로 예측모델을 개발하고 운영하고 있습니다.

\sphinxAtStartPar
어느날, 재미교포 카스트로씨가 카드사를 방문을 했습니다. 미국에 어렸을 적에 부모님과 같이 이민을 갔다가 다시 한국에 역이민을 왔는데 신용카드가 필요하다는 것입니다. 김대리는 고민에 빠졌습니다. 카스트로씨 같은 경우는 아직 국내 신용거래가 없어, 크레딧 뷰로에 데이터가 존재하지 않습니다. 카드 신청서 개인 정보도 제한적입니다. 예를 들어, 자가 보유 여부, 주택담보대출 여부 등의 정보가 없습니다. 즉, 운용하고 있는 연체 확률 모델을 활용할 수 가 없는 것입니다.

\sphinxAtStartPar
김대리는 이 문제를 해결하기 위해 사내에 있는 통계자료를 수집했습니다. 수집된 통계자료는 연령대별, 성별, 거주지별, 직장별로 평균 연체확률(아래 그림) 이 있습니다. 카스트로씨가 제공할 수 있는 개인정보는 (1) 연령, (2) 성별, (3) 거주지, (4) 직장정보가 전부였습니다. 김대리가 수집한 통계자료는 아래와 같습니다. 그리고 카스트로씨에 해당하는 부분을 회색으로 표시했습니다. 아래 정보를 이용하여 카스트로씨의 연체 확률을 추정할 수 있을까요?

\sphinxAtStartPar


\sphinxAtStartPar
좋은 아이디어가 떠오르지 않았습니다. 김 대리는 이전 직장상사 오 부장님께 전화를 걸었습니다. 오 부장님은 신용분석으로 경력이 20년이상 되신 분이라, 비슷한 경험이 있으실 것이라고 생각했는데, 정말 좋은 해결책을 알려주셨습니다. 오즈(odds) 를 이용한 방법이였습니다. 오즈(odds)란 ‘이벤트가 일어나지 않을 확률’ 대비 ‘이벤트가 일어날 확률’을 의미합니다. 김대리의 문제에서 오즈(odds) 는 (연체할 확률 / 연체하지 않을 확률) 로 계산이 될 수 있습니다. 아래는 오즈(odds) 계산 결과입니다.

\sphinxAtStartPar


\sphinxAtStartPar
또한, 오즈비(odds ratio) 에 대한 이해가 필요합니다. 카스트로씨 연령에 대한 오즈(odds) 는 0.026 이고, 전체 오즈(odds) 는 0.027 이므로, 전체 대비 연령의 오즈비(odds ratio) 는 0.026 를 0.027 로 나눈 0.961 입니다 . 이 값을 의미는 카스트로씨의 연체에 대한 odds 는 전체 odds 대비 96.1\% 낮다고 해석할 수 있습니다. 따라서 아무런 정보가 없는 카스트로씨의 오즈는 0.027 이였지만, 카스트로씨가 30대라는 사실을 알면 우리는 오즈를 조금 줄일 수 있습니다. 카스트로씨가 30대라는 정보를 입수하면, 카스트로씨의 오즈(odds) 는 0.027 * (0.026/0.027) 로 변경됩니다.

\sphinxAtStartPar
같은 방법으로 많은 정보가 많을 수록 카스트로씨의  odds 가 구체화 됩니다. 연령, 성별, 거주지, 지역 정보를 반영하면 카스트로 씨의 odds ratio 는 아래 공식으로 계산을 할 수 있습니다. 카스트로씨의 odds = (전체 odds) * (연령 odds ratio) * (성별 odds ratio) * (거주지 odds ratio) * (직장 odds ratio). 이 공식의 계산 결과는 0.029 가 됩니다. 오즈(odds) 는 P / (1\sphinxhyphen{}P)  즉, ‘연체할 확률’ / ‘연체하지 않을 확률’이므로 P 로 풀어쓰면, 연체 확률 P 는 odds / (1 + odds) 가 됩니다. P 를 계산하면 카스트로씨가 연체할 확률은 2.79\% 가 됩니다. 따라서 김대리는 연체확률 2.79\% 에 해당하는 신용한도를 부여하면 합리적인 결정이라고 할 수 있습니다. 특히 신용관리 부서는 “왜 그런 결론을 내렸는지?” 에 대하여 고객에게 설명을 할 수 있어야 합니다. 예를 들면 “내 옆집은 신용한도가 천만원인데 나는 오백만원이가요? 등의 민원이 있을 수 있습니다. 머신러닝 기반 모델 들은 명확한 해석이 불가능해서 이런 종류의 민원을 근본적으로 해결하지 못합니다. 통계 기반의 모델은 결과에 대한 설명이 가능하므로 이런 종류의 민원에 대응이 가능합니다. 따라서 많은 금융기관이 통계적인 모델링 방식을 아직 선호하고 있습니다.

\sphinxAtStartPar
이 사례에서 데이터 분석을 공부하셨던 분들은 로지스틱 회귀분석과 비슷하다고 느끼 셨을 것입니다. 맞습니다. 위 해결책은 로지스틱 회귀분석 모델링과 동일합니다.
참고로 로지스틱 회귀모델은

\sphinxAtStartPar
\( \ln(odds) \) 를 \( _X \) 의 선형조합 \( (b_0 + b_1 \cdot x_1 + b_2 \cdot x_2 + b_3 \cdot x_3 + b_4  \cdot x_4) \)  의 형태로 설명하는 모델입니다.

\sphinxAtStartPar
\( (카스트로씨 \ odds) \ 는 \ (전체 \ odds) * (연령\ odds\ ratio) * (성별\ odds\ ratio) * (거주지\ odds\ ratio) * (직장\ odds\ ratio) \)로 추정할 수 있다고 사례에서 설명드렸습니다.

\sphinxAtStartPar
양변에 \(log\) 를 씌우면,

\sphinxAtStartPar
\( \ln(카스트로씨\ odds) = \ln(전체\ odds)  + \ln(연령\ odds\ ratio) + \ln(성별\ odds\ ratio)\)\( + \ln(거주지\ odds\ ratio) + \ln(직장\ odds\ ratio) + \ln(직장\ odds\ ratio) \)

\sphinxAtStartPar
따라서,

\sphinxAtStartPar
\( \ln(전체\ odds)\ 는 \ b_0 \),  \( \ln(연령\ odds\ ratio)\ 는\ (b_1 \cdot x_1) \) 에 해당한다는 것을 알 수 있습니다.\( x_1 \) 이 (0,1) 의 바이너리 값이라면 \( b_1 \) 은 해당 연령의 \( odds\ ratio \) 에 \( log \) 를 한 값임을 알 수 있습니다.




\part{소매업 사례}
\label{\detokenize{chapter3/3.1.3_Use_Case:id1}}\label{\detokenize{chapter3/3.1.3_Use_Case::doc}}
\sphinxAtStartPar
문제해결을 위하여 데이터분석을 하는 경우가 대부분입니다.  처음 보험사 사례에서 설명드린 것과 같이 가설을 세우고, 가설을 검증하기 위하여 데이터분석을 합니다. 검증된 가설은 문제해결의 근거가 됩니다. 다른 접근법은 데이터베이스를 알고리즘으로 분석해 패턴을 찾아내는 방법인데, 이를 데이터마이닝 접근법이라고 부릅니다. 이 번 사례에서는 데이터 마이닝 사례 두 가지를 소개하겠습니다.

\sphinxAtStartPar
월마트는 미국의 큰 소매업체입니다. 우리나라 이마트 정도가 비슷할 것 같은데요. 카트에 사고 싶은 물건을 담고, 계산대에서 일괄로 지불합니다. 그 때 구매내역이 찍힌 영수증이 발행됩니다. 이 데이터는 월마트 내부 전산시스템에도 동일하게 저장이 되게 됩니다. 데이터분석가가 어떤 상품들이 같이 판매가 되는지 궁금해 분석을 해 보았습니다. 이 분석은 장바구니 분석(Market Basket Analysis)라고도 부릅니다. 이상하게 금요일 오후에 맥주와 아기 기저귀와 같은 영수증에 동일하게 찍히는 경우가 많다는 것이 분석 결과로 도출되었습니다. 이 사실을 영업총괄 매니저에게 보고를 했고, 총괄 매니저는 맥주 옆에 기저귀를 같이 진열을 해 보았습니다. 그 결과는 맥주와 아기 기저귀 매출이 두 배로 증가했습니다. 의아하게 생각한 매니저는 금요일 진열대 옆에서 어떤 고객들이 맥주와 기저귀를 같이 구매를 하는 지 관찰 해 보았습니다. 알고 보니, 금요일 퇴근한 젊은 아빠들이 스트레스를 받은 표정(와이프의 요청으로 퇴근 후에 피곤한 몸을 이끌고 마트에 온 것으로 추정)으로 기저귀를 사러왔다가 맥주도 같이 사가는 것이였습니다. 이렇듯 데이터마이닝으로 생각하지 못했던 통찰(Insight)를 얻을 수 도 있습니다.

\sphinxAtStartPar
이번에는 타겟 사례입니다. 타겟은 미국의 카탈로그 소매업체입니다. 타겟은 임산부를 위한 특별한 프로모션을 준비했고, 임산부에게 임신기간 중 필요한 다양한 상품을 소개하는 카탈로그 준비했습니다. 일단 임신을 하게되면, 출산과 육아기간 동안 필요한 제품들이 정해져 있는데요. 타겟은 그것을 노리고 대대적인 프로모션을 계획한 것입니다. 카탈로그는 독자 이름으로 우편 배달이 되는데요. 이 임산부용 카탈로그가 어느 한 여고생 집으로 배달이 된 것이였습니다. 그 사실은 안 학생 아버지는 화가 잔뜩 나서 회사에 전화를 걸어 항의했습니다. “우리 아이가 고등학생인데, 무슨 임산부 카탈로를 보내느냐? 당장 담당자가 직접와서 사과를 하지 않으면 업체를 고소하겠다”  그런데 몇 일 후 학생은 아버지에게 이런 이런 일로 임신을 했다고 고백을 하게되었습니다. 타겟의 고객 담당자는 몇 일 후 집으로 찾아왔고, 아버지는 이 사실을 이야기 할 수 밖에 없었습니다. 그렇다면, 타겟은 이 여고생이 임신한 사실을 어떻게 알았을까요?  타겟의 데이터 분석가는 임산부의 구매특성에 대하여 분석을 했었는데요. 대부분의 고객은 임신을 하게되면, 피부 로션과 헤어 샴푸를 화학성분이 없고, 향이 강하지 않은 오가닉 제품으로 변경한다는 사실을 발견했습니다. 바로 그 여고생이 제품을 오가닉으로 갑자기 변경한 고객 중의 하나였던 것입니다. 물론 연령을 고려하지 않은 타겟팅을 한 잘못이 있다고 생각됩니다. 타겟의 에피소드 역시 구매이력 데이터베이스를 분석하다가 예상하지 못한 것을 발견하고 마케팅에 활용한 데이터마이닝 사례 중 하나입니다.


\part{제조업 사례 (난이도 상)}
\label{\detokenize{chapter3/3.1.4_Use_Case:id1}}\label{\detokenize{chapter3/3.1.4_Use_Case::doc}}
\sphinxAtStartPar
제조업의 데이터분석은 금융업이나 소매업보다 조금 더 복잡합니다.  이 제조업 사례의 문제를 풀기 위해서는 두 가지 지식이 필요한데요. 하나는 최소자승법(Least Square Method)이고 다른 하나는 선형계획법(Linear Programming) 입니다.  철강업체 A 에서 환경관리를 담당하고 있는 여과장은 용해 후에 최종적으로 납품되는 Alloy(금속합금) 의 성분에 독성이 강한 X 물질이 다량 함유 되어 있다는 것을 알았습니다. 이 독성물질 X 는 함유율이 임계점 0.05\% 이상되었을 때 독성이 강하게 나타납니다. 따라서, 최종 합금 Alloy 에 독성 물질이 0.05\% 이하가 되도록 관리를 하고 싶습니다. Alloy 는 10 개의 공급 업체에서 금속 Scrap (스크랩) 를 납품받은 후, 몇 개의 업체 Scrap 을 선별 후, 용해해서 만듭니다. 첫 번째 문제는 각 업체에서 공급하는 Scrap 에 함유되어 있는 X 물질의 함유율을 정확히 모르고, 두 번째 문제는 X 물질의 함유율이 낮을 수 록 Scrap 단가가 비싸다는 것입니다. X 물질 함유율이 낮은 Scrap 만을 골라서 용해를 하면 독성 물질 X 함유율을 0.05\% 이하로 관리할 수 있으나, 비용 증가의 문제가 생깁니다. 결국 풀고자하는 문제는 최소한의 비용으로 독성물질의 함유율이 0.05\% 이하가 되도록 Alloy 합금을 만드는 것입니다.

\sphinxAtStartPar
여과장은 아래와 같이 배치( Batch) 데이터베이스를 만들었습니다. 아래 테이블은 샘플 배치 3 개를 보여주고 있습니다. 예를 들어 첫 번째 배치 B123 에는 3 개 업체의 Scrap 이 각 13톤, 5톤, 12톤이 투입되었습니다. 최종적으로 30 톤의 Alloy 가 만들어졌는데요. 독성물질 X 의 함유량을 측정해 보니 0.07\% 가 들어있었고, 이 배치는 0.05\% 를 넘어갔으므로 불합격입니다.  만약 여과장이 각 업체  Scrap 의 X 함유율 P1 \textasciitilde{} P10 을 알고 있다면, 최소비용으로 Alloy 를 만드는 방법을 선형계획법을 풀 수 가 있습니다. 먼저 선형 계획법으로 문제를 풀어보겠습니다.



\sphinxAtStartPar
위 문제를 선형 계획법으로 도식화하면 아래와 같습니다. 배치의 총 비용을 목적함수으로 하고, 목적함수를 최소화하는 투입량  Wi  을 찾습니다. 단, 투입 후 물질 X 의 함유량이 0.05\% 이하여야 한다는 제약이 있습니다.  아래에서 각 \( W,\ C,\ P \) 는  다음을 의미합니다.
\( W \): Weight, \( C \): Cost,  \( P \): Proportion

\sphinxAtStartPar
\sphinxstylestrong{Minimize} \( \sum\ \) \( [ W_i \) * \( C_i  \ ] \) (비용 목적함수) for \( vendor = i \)

\sphinxAtStartPar
\sphinxstylestrong{(제약식)}

\sphinxAtStartPar
\( [ W_i \)* \( P_i  \ ] \) \(\ <= \) \(∑ \ W_i \ * \ 0.05\% \) (물질 X 의 함유량 제약)\( \sum\ W_i \)  =  (필요한 총 톤 수 제약)

\sphinxAtStartPar
이제 여과장은 각 업체의 물질 X 함유량 P 만 알면 위 선형계획법을 활용하여 최소비용으로 Alloy 를 생산하는 업체별 Scrap 투입량  W 를 알아낼 수 있습니다. 파이썬에서 선형계획법(Linear Programming) 은 PuLp 라이브러리에서 구현할 수 있습니다..

\sphinxAtStartPar
문제는 어떻게  함유량 P1 \textasciitilde{} P10 를 알아내는냐입니다. 사실 이 문제를 푸는 방법은 여러가지가 있습니다. 여과장은 최소자승법으로 문제를 풀었는데요. 어떻게 풀었는지 함 보겠습니다.  만약 우리가 P1 \textasciitilde{} P10 을 알고 있다면 각 배치별 물질 X 의 총량은 아래와 같이 추정할 수 있을 것입니다. 그렇다면 추정치 함유량과 실제 함유량의 차이가 최소가 되는 P1 \textasciitilde{} P10 을 찾는 것입니다.









\renewcommand{\indexname}{Index}
\printindex
\end{document}